{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf0e72e-4f5d-43cf-83c6-889d9dcea1fc",
   "metadata": {},
   "source": [
    "# Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\n",
    "\n",
    "<center>\n",
    "<img \n",
    "     src=\"http://www2.famaf.unc.edu.ar/~efernandez/egeo/img/logos/famaf.jpg\" \n",
    "     alt=\"Drawing\" \n",
    "     style=\"width:30%;\"\n",
    "/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfd514d-a3ac-4e0d-acb0-abb1a6f5c4ec",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d388b71c-7b51-4977-99e8-f6a1282cd524",
   "metadata": {},
   "source": [
    "# Practico: Aprendizaje Supervisado\n",
    "\n",
    "El objetivo consiste en explorar la aplicación de diferentes métodos de aprendizaje supervisado aprendidos \n",
    "en el curso, a través de experimentos reproducibles, y evaluando a su vez la conveniencia de uno u otro, \n",
    "así como la selección de diferentes hiperparámetros a partir del cálculo de las métricas pertinentes.\n",
    "\n",
    "*Leer atentamente todas las consignas antes de empezar a trabajar, cualquier duda escriban a algún mentor*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1027c75-fe5d-4342-a170-746d0bd7d665",
   "metadata": {},
   "source": [
    "# Primera parte: Preparacion de los sets de datos\n",
    "\n",
    "\n",
    "#### Consigna: Obtener un dataset de los tres pacientes, y uno mas por cada paciente, dando como reslutado 4 datasets. \n",
    "\n",
    "En base a lo visto hasta el momento, quizás sea mas predecible el estado pre-ictal separando el análisis por paciente. Vamos a evaluar esta teoria comparando el desempeño de los modelos. Para eso necesitamos los datasets separados. \n",
    "\n",
    "----\n",
    "\n",
    "#### Consigna: Hacer **filtros de outliers** (ver archivo de ejemplo) especifico para cada paciente y para los tres juntos\n",
    "\n",
    "Si bien el tratamiento de escalado y curado de datos nulos es igual es igual que en el practico de curacion, no aplica para el estudio de outliers, por lo que debera ser realizado nuevamente, esta vez especifico por cada paciente, ademas de en grupo.\n",
    "\n",
    "----\n",
    "\n",
    "Al final de esta parte deberian tener cuatro datasets y cuatro filtros de outliers\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f1ffd-d190-475f-a3b2-9eb8d56d8a0a",
   "metadata": {},
   "source": [
    "# Segunda parte: Estudio de clasificadores\n",
    "\n",
    "#### Consigna: instanciar un modelo inicial que se usará como base para comparar con otros modelos. Usar un modelo lineal (ver archivo de ejemplo)\n",
    "\n",
    "El modelo base es una primera aproximación. No necesariamente estamos en busqueda de ajustar hiperparametros para incrementar unas decimas el F1-Score, sino que mas bien queremos conocer la performance del modelo en su ajuste mas basico. De esa manera cuando comencemos a ajustar mas y usar otros modelos no lineales, sabemos que no deberiamos tener algo peor al base. \n",
    "\n",
    "---\n",
    "#### Consigna: Elegir y justificar un modelo para seleccion de features\n",
    "\n",
    "Ya se vió que puede existir cierta correlación entre algunas de nuestras features. Para asegurar la efectividad del dataset, vamos a usar algun modelo que prediga cuales son los mejores features.\n",
    "\n",
    "Fuente: https://towardsdatascience.com/feature-selection-using-logistic-regression-model-efc949569f58\n",
    "\n",
    "---\n",
    "#### Consigna: Estudien, prueben, y diagnostiquen distintos clasificadores sobre nuestros set de datos. \n",
    "\n",
    "Prueben el dataset etiquetado separando por paciente y con el dataset completo (sin la columna de paciente). Por cada modelo: \n",
    "\n",
    "- Aplicar un selector de features\n",
    "- Estudiar que los hiperparametros se ajusten a nuestro dataset. \n",
    "- Refinar la busqueda de hiperparametros usando gridsearchCV o RandomSearchCV (recuerden que mucho antes de los hiperparametros, son los features los que mas determinan la efectividad del modelo). \n",
    "\n",
    "\n",
    "Modelos propuestos (no limitarse a):\n",
    "\n",
    "- Lineal (modelo base): LogisticRegression, SGDClassifier. _Fuente: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model_\n",
    "- SVM: SVC, NuSVC, LinearSVC. _Fuente: https://scikit-learn.org/stable/modules/svm.html_\n",
    "- Ensemble:  BaggingClassifier, KNeighborsClassifier, RandomForestClassifier. _Fuente: https://scikit-learn.org/stable/modules/ensemble.html_\n",
    "- Opcional:\n",
    "    - Deep Learning: Keras Sequential (ver ejemplo)\n",
    "\n",
    "\n",
    "Por cada modelo usado deberia haber algun analisis sobre los hiperparametros que mejor se acomodan a nuestro dataset. No es necesario que se limiten a la lista propuesta de metodos. Pero deberia haber como minimo un modelo base, dos de SVM y dos de Ensemble. Pueden opcionalmente usar el VotingClassifier para combinar los resultados de los clasificadores usados en un modelo nuevo\n",
    "\n",
    "#### Consigna: Armar una grilla de resultados (ver archivo de ejemplo) y realizar conclusiones.\n",
    "\n",
    "Nota: Recuerden que las conclusiones no son unicamente acerca de cual es el mejor modelo. Cada modelo que instancian sufre una serie de modificaciones que pueden devenir de la teoria o mas bien de la prueba y el error. El resgistro del analisis sobre el desempeño de los modelos nos va a permitir evaluarlos y ubicarlos en el contexto de nuestro dataset particular.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03ce1d-3d10-455b-a183-76b7e16431fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
