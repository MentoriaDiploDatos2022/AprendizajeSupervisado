{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4288d6a0-99d3-48b7-ba19-ac6367dfb5d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Guia completa: https://www.pluralsight.com/guides/classification-keras\n",
    "\n",
    "Keras es una API de redes neuronales de alto nivel, escrita en Python, y puede ejecutarse sobre TensorFlow, CNTK o Theano. Una de las ventajas es que permite una primera aproximación al deep learning. \n",
    "\n",
    "Las RN consumen muchos mas recursos de cómputo y por eso solo se usan en situaciones que lo ameritan. Ademas, el algoritmo que se genera en las capas intermedias es prácticamente inaccesible y por lo tanto no se tiene un control sobre el mismo como el que si tendríamos con otros algoritmos.\n",
    "\n",
    "Planteo este ejercicio opcional sobre RN porque es un algoritmo muy popular y seria interesante analizar el desempeño sobre nuestro dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "478ddb84-51e4-497b-ad9d-76fe95d1eb8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "# Obtenemos los datos\n",
    "\n",
    "df_etiquetados = []\n",
    "df_no_etiquetados = []\n",
    "filedir = \"data_preprocessed\"\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "for file in listdir(filedir):\n",
    "    if file[-4:] == \".csv\":\n",
    "        if \"noEtiquetado\" in file: df_no_etiquetados.append(pd.read_csv(f\"{filedir}/{file}\"))\n",
    "        else: df_etiquetados.append(pd.read_csv(f\"{filedir}/{file}\"))\n",
    "    else: print(file, \" ---> no es csv\")\n",
    "\n",
    "for df in df_etiquetados: assert len(df.columns) == 11\n",
    "for df in df_no_etiquetados: assert len(df.columns) == 10\n",
    "    \n",
    "df = pd.concat(df_etiquetados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb31e8-a8d4-422e-999c-fca9a0763b50",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtro de outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85169049-7e4d-42e6-a043-768fe36ff565",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5849 entries, 0 to 2393\n",
      "Data columns (total 11 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Patient  5849 non-null   float64\n",
      " 1   State    5849 non-null   float64\n",
      " 2   PE       5849 non-null   float64\n",
      " 3   SC       5849 non-null   float64\n",
      " 4   GNE      5849 non-null   float64\n",
      " 5   SE       5849 non-null   float64\n",
      " 6   LZC      5849 non-null   float64\n",
      " 7   STE      5849 non-null   float64\n",
      " 8   Mean     5849 non-null   float64\n",
      " 9   Std      5849 non-null   float64\n",
      " 10  Skew     5849 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 548.3 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-80ecba153e75>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dff.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Aplico un filtro a cada columna y reasigno con el df original.\n",
    "def outlier_filter(df, c, low, top):\n",
    "    return df[(df[c] > low) & (df[c] < top)]\n",
    "\n",
    "\n",
    "# Elimino outliers para cada columna con metodo de cuantiles\n",
    "for col in df.columns:\n",
    "    low = df[col].quantile(0.01)\n",
    "    top = df[col].quantile(0.99)\n",
    "    dff = outlier_filter(df, col, low, top)\n",
    "    \n",
    "# Elimino nulos\n",
    "dff.dropna(inplace=True)\n",
    "\n",
    "df = dff\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2ea225-5a4e-4fd6-bc3c-a0b6c55c9480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos features de etiqueta\n",
    "X = df.drop(labels=['State','Patient'], axis=1)\n",
    "y = df['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d916b1e3-8265-407f-8ad7-8b86260ae999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951f215-3a4c-4ee8-ab32-321ddff34370",
   "metadata": {},
   "source": [
    "## Instanciacion del modelo\n",
    "\n",
    "Vamos a usar el constructor Sequential porque nuestra RN consiste en una pila de capas lineales. \n",
    "\n",
    "Las segunda linea de codigo representa la capa de entrada que especifica la *funcion de activacion* y la cantidad de dimensiones de entrada, que en nuestro caso corresponde a los 9 features. Repetimos este proceso para dos capas ocultas siguientes, sin el parametro de numero de inputs. Usamos como funcion de activacion a la unidad de rectificacion lineal ReLU (pueden elegir otra).\n",
    "\n",
    "La ultima capa es la de salida y tiene dos nodos porque tenemos dos etiquetas: 0 y 1. Usamos softmax como funcion de activacion para la capa de salida par aque la suma de todos los valores predecidos de todos los nodos en la capa de salida suma 1.\n",
    "\n",
    "La funcion compile() configura el proceso de aprendizaje y estan seteados algunos parametros. Usamos categorical_crossentropy como funcion de perdida, 'adam' el algoritmo de optimizacion, y 'recall' nuestra metrica de evaluacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df5fe66b-e628-4a9a-9f32-74ea090aba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_dim=9))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f35bf-b59c-44f3-97cb-91e9c4701029",
   "metadata": {},
   "source": [
    "Instanciamos el modelo con 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7720549-dd16-4f83-afad-e499bc1ba6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "128/128 [==============================] - 0s 977us/step - loss: 0.7010 - accuracy: 0.5161\n",
      "Epoch 2/20\n",
      "128/128 [==============================] - 0s 891us/step - loss: 0.6931 - accuracy: 0.4685\n",
      "Epoch 3/20\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4902\n",
      "Epoch 4/20\n",
      "128/128 [==============================] - 0s 906us/step - loss: 0.6931 - accuracy: 0.5017\n",
      "Epoch 5/20\n",
      "128/128 [==============================] - 0s 875us/step - loss: 0.6931 - accuracy: 0.4983\n",
      "Epoch 6/20\n",
      "128/128 [==============================] - 0s 863us/step - loss: 0.6931 - accuracy: 0.5017\n",
      "Epoch 7/20\n",
      "128/128 [==============================] - 0s 871us/step - loss: 0.6931 - accuracy: 0.4922\n",
      "Epoch 8/20\n",
      "128/128 [==============================] - 0s 871us/step - loss: 0.6931 - accuracy: 0.5024\n",
      "Epoch 9/20\n",
      "128/128 [==============================] - 0s 879us/step - loss: 0.6932 - accuracy: 0.4951\n",
      "Epoch 10/20\n",
      "128/128 [==============================] - 0s 879us/step - loss: 0.6932 - accuracy: 0.4895\n",
      "Epoch 11/20\n",
      "128/128 [==============================] - 0s 953us/step - loss: 0.6934 - accuracy: 0.4939\n",
      "Epoch 12/20\n",
      "128/128 [==============================] - 0s 945us/step - loss: 0.6931 - accuracy: 0.4787\n",
      "Epoch 13/20\n",
      "128/128 [==============================] - 0s 875us/step - loss: 0.6932 - accuracy: 0.4990\n",
      "Epoch 14/20\n",
      "128/128 [==============================] - 0s 848us/step - loss: 0.6935 - accuracy: 0.5032\n",
      "Epoch 15/20\n",
      "128/128 [==============================] - 0s 852us/step - loss: 0.6933 - accuracy: 0.5181\n",
      "Epoch 16/20\n",
      "128/128 [==============================] - 0s 855us/step - loss: 0.6931 - accuracy: 0.4836\n",
      "Epoch 17/20\n",
      "128/128 [==============================] - 0s 856us/step - loss: 0.6931 - accuracy: 0.5017\n",
      "Epoch 18/20\n",
      "128/128 [==============================] - 0s 969us/step - loss: 0.6931 - accuracy: 0.4954\n",
      "Epoch 19/20\n",
      "128/128 [==============================] - 0s 855us/step - loss: 0.6932 - accuracy: 0.4944\n",
      "Epoch 20/20\n",
      "128/128 [==============================] - 0s 941us/step - loss: 0.6934 - accuracy: 0.5261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18fb84b2a90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b695473b-2455-4782-97c4-aa200011e2d7",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "The first line of code predicts on the train data, while the second line evaluates the model, and the third line prints the accuracy and error on the training data.\n",
    "\n",
    "The same is repeated in the fourth, fifth and sixth lines of code which is performed on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b3fa4b9-e89c-4c9b-bf22-55b3cb32b482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.8971666097640991% \n",
      " Error on training data: 0.10283339023590088\n",
      "Accuracy on test data: 0.9475783705711365% \n",
      " Error on test data: 0.052421629428863525\n"
     ]
    }
   ],
   "source": [
    "pred_train= model.predict(X_train)\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores[1], 1 - scores[1]))   \n",
    " \n",
    "pred_test= model.predict(X_test)\n",
    "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dedecad-ea17-4c77-820c-16a903c79457",
   "metadata": {},
   "source": [
    "Tenemos una accuracy del 90% para train y un 94% para test (sospechosamente alto). Fijense que ocurre cuando cambiamos el Shuffle=True en el train_test_split. Que esta pasando?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f791bc5-ff9c-4344-a884-0b263a005e1d",
   "metadata": {},
   "source": [
    "### Consigna\n",
    "\n",
    "- Aplicar este modelo sobre los datos dentro de sus criterios de outliers / curacion y balanceo de datos.\n",
    "- investigar sobre las mejores configuraciones del compiler para nuestros datos: optimizer, loss y metrics. \n",
    "- Evaluar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c286f4e-f7e1-48dc-a80b-02b15fa92cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
